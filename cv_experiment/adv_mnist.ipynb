{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the random seed, so the experiment is reproducible\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "# For the moment, we will just train on CPU, so no cuda\n",
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# We use a batch size of 32 examples while training, and 1000 while testing\n",
    "batch_size = 32\n",
    "test_batch_size = 1000\n",
    "# We will use SGD with a momentum term\n",
    "momentum = 0.5\n",
    "# The learning rate\n",
    "lr = 0.01\n",
    "# The number of epochs\n",
    "epochs = 3\n",
    "# The size of the input. MNIST are greyscale images, 28x28 pixels each\n",
    "im_size = 28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, train_losses):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9895936/9912422 [00:19<00:00, 423161.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 69020.27it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 8192/1648877 [00:01<01:18, 20933.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 16384/1648877 [00:01<01:08, 23800.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 32768/1648877 [00:01<00:53, 30458.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 73728/1648877 [00:02<00:38, 40891.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 114688/1648877 [00:02<00:28, 54004.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 155648/1648877 [00:02<00:21, 68927.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 204800/1648877 [00:03<00:24, 59531.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 221184/1648877 [00:03<00:28, 50091.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 262144/1648877 [00:04<00:20, 67441.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 303104/1648877 [00:04<00:15, 87082.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 327680/1648877 [00:04<00:15, 87860.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 360448/1648877 [00:04<00:14, 87019.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 376832/1648877 [00:05<00:16, 76293.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 425984/1648877 [00:05<00:12, 100019.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 483328/1648877 [00:05<00:08, 130846.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 516096/1648877 [00:05<00:07, 143602.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 581632/1648877 [00:05<00:05, 183129.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 655360/1648877 [00:05<00:04, 229880.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 712704/1648877 [00:05<00:03, 278620.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 761856/1648877 [00:06<00:02, 319355.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 827392/1648877 [00:06<00:02, 324691.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 909312/1648877 [00:06<00:03, 211352.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 1056768/1648877 [00:07<00:02, 278838.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 1114112/1648877 [00:07<00:01, 302449.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 1171456/1648877 [00:07<00:01, 329865.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 1228800/1648877 [00:07<00:01, 368153.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 1286144/1648877 [00:07<00:00, 404840.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 1359872/1648877 [00:07<00:00, 444860.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 1417216/1648877 [00:07<00:00, 466687.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 1474560/1648877 [00:07<00:00, 440612.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 1531904/1648877 [00:08<00:00, 461997.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "1654784it [00:08, 198206.80it/s]                             \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8192it [00:00, 26285.39it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9920512it [00:29, 423161.73it/s]                             \n",
      "32768it [00:20, 69020.27it/s]                           \u001b[A"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example, label) = next(examples)\n",
    "example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADhCAYAAAD2+m+FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKqARUQi+X9L+CY8Y09QvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(8):\n",
    "  plt.subplot(2,4,i+1)\n",
    "  plt.imshow(example[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Label: {}\".format(label[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "model = MLP().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.198369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.155087\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.131146\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.073608\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.029857\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.185125\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.241926\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.106881\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.092932\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.193102\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.114658\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.244189\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.172704\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.329610\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.275037\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.290272\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.215232\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.122801\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.076389\n",
      "\n",
      "Test set: Average loss: 0.1198, Accuracy: 9648/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.098149\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.248148\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.060891\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.176344\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.027461\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.073619\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.029013\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.062051\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.187532\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.127641\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.043857\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.217135\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.217773\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.162997\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.156015\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.041070\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.064530\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.127780\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.059724\n",
      "\n",
      "Test set: Average loss: 0.1124, Accuracy: 9663/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.053829\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.168619\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.082475\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.019769\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.151956\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.041617\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.145623\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.353926\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.041855\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.193399\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.036656\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.050950\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.097500\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.130437\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.231027\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.028303\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.057398\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.086400\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.271931\n",
      "\n",
      "Test set: Average loss: 0.1048, Accuracy: 9693/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_losses = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, training_losses)\n",
    "    test(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
